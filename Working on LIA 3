# Collaborators: Mia Doan (2483330) & Kaira Sotelo (6293070)


# Imports 
import pandas as pd 
import seaborn as sns 
import matplotlib.pyplot as plt 
import numpy as np 

# Dataset 
data = pd.read_csv("Forest_Fires_Dataset")
df = pd.read_csv("Forest_Fires_Dataset")


# Q2. Prelimiary steps
# a) Initial Data Inspection: 
print()
print(data.head())
print("Number of rows and columns in the dataset:")
print(data.shape())
print("Summary of dataset:")
print(data.info())
print("Basic descriptive statistics for each column:")
print(data.describe())
print("Type of value in each column:")
print(data.dtypes())
print("Memory usage of each column")
print(data.memory_usage())

# b) Handle duplicate entries
print()
print("Number of duplicated rows:")
print(data.duplicated())
print("After removing duplicates:")
print(data.drop_dupliactes())

# c) Identify and manage missing values
print()
print(data.isnull)
#!!!!!!!!!!!!

# d) Correct data types and formats
print()
print(pd.to_datetime())
print(pd.to_numeric())


# Q3. Univariate non-graphical EDA
print()
print("The mean is:")
print(pd.mean())
print("The median is:")
print(pd.median())
print("The mode is:")
print(pd.mode())
print("The standard deviation is:")
print(pd.std())
print("The variance is:")
print(pd.var)
print("The skewness is:")
print(pd.skew())
print("The kurtosis is:")
print(pd.kurtosis())
print("The quartiles are:")
print(pd.quantile[0.25, 0.5,0.75])

#For each categorical varaibles

for col in df.select_dtypes(exclude=[np.number]):
    print("The frequency count is:")
    print(df[col].value_counts())
    print("The proportion is")
    print(df[col].value_counts(normalize=True) * 100)
    # The normalize = True calculates the relative frequency (proportion) and * 100 changes the values into percentage
    print("The mode is")
    print(df[col].mode()[0])
    print("The number of unique categories:")
    print(df[col].nunique())
    
#Q4. Univariate graphical EDA
#Section 1: visualizing distribution of data 

#select only numeric columns
numeric_cols = df.select_dtypes(include=[np.number]).columns

#Loop through each numeric variable
for col in numeric_cols:
    #a)Histograms with custom and appropriate number of bins
    sns.histplots(df[col], bins=20, kde=False, color="blue")
    plt.title("Histogram of {col} for 20 bins")
    plt.xlabel(col)
    plt.ylabel("count")
    plt.show()
    
    
    #b) Conditioning on other variables using jurisdiction for example
    if "jurisdiction" in df.columns: 
        sns.histplot(data=df, x=col, hue="jurisdiction", bins=15)
        plt.title("{col} by jurisdiction")
        plt.xlabel(col)
        plt.ylabel("count")
        plt.show()
        
    #c) Stacked histogram
    if "jurisdiction" in df.columns:
        sns.histplot(data=df, x=col, hue="jurisdiction", multiple = "stack", bins=15)
        plt.title("stacked histograms of {col} by jurisdiction")
        plt.xlabel(col)
        plt.ylabel("count")
        plt.show()
        
    #d) Dodge bars
    if "jurisdiction" in df.columns: 
        sns.histplot(data=df, x=col, hue="jurisdiction", multiple="dodge", bins=15)
        plt.title("Dodge histogram of {col} by jurisdiction")
        plt.xlabel(col)
        plt.ylabel("count")
        plt.show()
        
    #e) Normalized histogram statistics
    sns.histplot(df[col], bins=15, stat="count", color="red")
    plt.title("Normalized histogram (count) of {col}") 
    plt.xlabel(col)
    plt.ylabel("count")
    plt.show()
        
    #f)  Kernel density estimation (choosing the smoothing bandwidth)
    sns.kdeplot(df[col], )
